
<!DOCTYPE html>
<html lang="en-US">
<head>
<meta charset="UTF-8" />
<meta name="author" content="Some Author" />
<meta name="generator" content="LaTeX Lwarp package" />
<meta name="description" content="A description." />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<!--[if lt IE 9]>
<script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
<title>Webpage Title — spaCy Tutorials</title>
<link rel="stylesheet" href="prism.css" type="text/css">
<script src="prism.js" type="text/javascript"> </script>
<link rel="stylesheet" type="text/css" href="lwarp_sagebrush.css" />



<script>
// Lwarp MathJax emulation code
//
// Based on code by Davide P. Cervone.
// Equation numbering: https://github.com/mathjax/MathJax/issues/2427
// Starred and ifnextchar macros: https://github.com/mathjax/MathJax/issues/2428
//
// Modified by Brian Dunn to adjust equation numbering and add subequations.
//
// LaTeX can use \seteqnumber{subequations?}{section}{number} before each equation.
// subequations? is 0 usually, 1 if inside subequations.
// section is a string printed as-is, or empty.
// number is auto-incremented by MathJax between equations.
//
MathJax = {
     subequations: "0",
     section: "",
     loader: {
         load: ['[tex]/tagFormat']
     },
     startup: {
         ready() {
             //       These would be replaced by import commands if you wanted to make
             //       a proper extension.
             const Configuration = MathJax._.input.tex.Configuration.Configuration;
             const CommandMap = MathJax._.input.tex.SymbolMap.CommandMap;
             const Macro = MathJax._.input.tex.Symbol.Macro;
             const TexError = MathJax._.input.tex.TexError.default;
             const ParseUtil = MathJax._.input.tex.ParseUtil.default;
             const expandable = MathJax._.util.Options.expandable;


             //       Insert the replacement string into the TeX string, and check
             //       that there haven't been too many maxro substitutions (prevents
             //       infinite loops).
             const useArgument = (parser, text) => {
                  parser.string = ParseUtil.addArgs(parser, text, parser.string.slice(parser.i));
                  parser.i = 0;
                  if (++parser.macroCount > parser.configuration.options.maxMacros) {
                      throw new TexError('MaxMacroSub1',
                      'MathJax maximum macro substitution count exceeded; ' +
                      'is there a recursive macro call?');
                  }
             }


             //       Create the command map for \ifstar, \ifnextchar, \seteqnumber
             new CommandMap('ifstar-ifnextchar-setequnumber', {
                  ifstar: 'IfstarFunction',
                  ifnextchar: 'IfnextcharFunction',
                  seteqnumber: 'SeteqnumberFunction'
             }, {
                  //      This function implements an ifstar macro.
                  IfstarFunction(parser, name) {
                      const resultstar = parser.GetArgument(name);
                      const resultnostar = parser.GetArgument(name);
                      const star = parser.GetStar();                        // true if there is a *
                      useArgument(parser, star ? resultstar : resultnostar);
                  },


                  //      This function implements an ifnextchar macro.
                  IfnextcharFunction(parser, name) {
                      let whichchar = parser.GetArgument(name);
                      if (whichchar.match(/^(?:0x[0-9A-F]+|[0-9]+)$/i)) {
                          // $ syntax highlighting
                          whichchar = String.fromCodePoint(parseInt(whichchar));
                      }
                      const resultnextchar = parser.GetArgument(name);
                      const resultnotnextchar = parser.GetArgument(name);
                      const gotchar = (parser.GetNext() === whichchar);
                      useArgument(parser, gotchar ? resultnextchar : resultnotnextchar);
                  },


                  //      This function modifies the equation numbers.
                  SeteqnumberFunction(parser, name) {
                          //   Get the macro parameters
                          const star = parser.GetStar();                       // true if there is a *
                          const optBrackets = parser.GetBrackets(name);        // contents of optional brackets
                          const newsubequations = parser.GetArgument(name);       // the subequations argument
                          const neweqsection = parser.GetArgument(name);       // the eq section argument
                          const neweqnumber = parser.GetArgument(name);        // the eq number argument
                          MathJax.config.subequations=newsubequations ;        // a string with boolean meaning
                          MathJax.config.section=neweqsection ;                // a string with numeric meaning
                          parser.tags.counter = parser.tags.allCounter = neweqnumber ;
                  }
             });


             //       Create the ifstar-ifnextchar-setequnumber package
             Configuration.create('ifstar-ifnextchar-setequnumber', {
                  handler: {macro: ['ifstar-ifnextchar-setequnumber']}
             });


             MathJax.startup.defaultReady();


             // For forward references:
             MathJax.startup.input[0].preFilters.add(({math}) => {
                  if (math.inputData.recompile){
                          MathJax.config.subequations = math.inputData.recompile.subequations;
                          MathJax.config.section = math.inputData.recompile.section;
                  }
             });
             MathJax.startup.input[0].postFilters.add(({math}) => {
                  if (math.inputData.recompile){
                          math.inputData.recompile.subequations = MathJax.config.subequations;
                          math.inputData.recompile.section = MathJax.config.section;
                  }
             });
         }       // ready
     },           // startup


     tex: {
         packages: {'[+]': ['tagFormat', 'ifstar-ifnextchar-setequnumber']},
         tags: "ams",
                  tagFormat: {
                          number: function (n) {
                               if(MathJax.config.subequations==0)
                                      return(MathJax.config.section + n);
                               else
                                      return(MathJax.config.section + String.fromCharCode(96+n));
                          },
                  },
     }
}
</script>


<script
         id="MathJax-script"
         src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"
></script>

</head>
<body>


<a id="postGrad-autopage-21"></a>
<nav class="topnavigation" ><a href="index.html" class="linkhome" >
Home</a></nav>

<header>

<p>
<span
    class="fbox"
    style="display:inline-block ; border:1pt solid #000000; padding:3pt ; color:#000000"
>LOGO</span>
</p>

</header>


<div class="bodyandsidetoc" >
<div class="sidetoccontainer" >


<nav class="sidetoc" >


<div class="sidetoctitle" >

<p>
<span class="sidetocthetitle" >The Lwarp Tutorial</span>
</p>

<p>
Contents
</p>
</div>


<div class="sidetoccontents" >

<p>
<a href="index.html" class="linkhome" >
Home</a>
</p>

<p>
<a href="Example-chapter.html#autosec-8" class="tocchapter" >
<span class="sectionnumber" >1</span>&#x2003;Example chapter</a>
</p>


<p>
<a href="Example-chapter.html#autosec-9" class="tocsection" >
<span class="sectionnumber" >1.1</span>&#x2003;A section</a>
</p>


<p>
<a href="Some-math.html#autosec-16" class="tocsection" >
<span class="sectionnumber" >1.2</span>&#x2003;Some math</a>
</p>


<p>
<a href="2020.html#autosec-18" class="tocpart" >
<span class="sectionnumber" >I</span>&#x2003;2020</a>
</p>


<p>
<a href="2020.html#autosec-19" class="tocsection" >
<span class="sectionnumber" >1.3</span>&#x2003;Setting up Rasa on GCP</a>
</p>


<p>
<a href="spaCy-Tutorials.html#autosec-22" class="tocchapter" >
<span class="sectionnumber" >2</span>&#x2003;spaCy Tutorials</a>
</p>


<p>
<a href="spaCy-Tutorials.html#autosec-23" class="tocsection" >
<span class="sectionnumber" >2.1</span>&#x2003;Spacy Code Tutorials</a>
</p>


<p>
<a href="Real-Content.html#autosec-56" class="tocchapter" >
<span class="sectionnumber" >3</span>&#x2003;Real Content</a>
</p>


<p>
<a href="Real-Content.html#autosec-59" class="tocsection" >
<span class="sectionnumber" >3.1</span>&#x2003;SQL</a>
</p>


<p>
<a href="Index-0.html#autosec-72" class="tocchapter" >
Index</a>
</p>


<p>
<a href="Index-0.html#autosec-75" class="tocchapter" >
Glossary</a>
</p>


<p>
<a href="Index-0.html#autosec-77" class="tocchapter" >
Acronyms</a>
</p>


</div>

</nav>

</div>


<div class="bodycontainer" >


<section class="textbody" >

<h1>The Lwarp Tutorial</h1>

<!--MathJax customizations:-->


<div class="hidden" >

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

</div>

<p>
<h3 id="autosec-22"><span class="sectionnumber" >2&#x2003;</span>spaCy Tutorials</h3>
<a id="postGrad-autopage-22"></a>
<a id="postGrad-autofile-4"></a>
<h4 id="autosec-23"><span class="sectionnumber" >2.1&#x2003;</span>Spacy Code Tutorials</h4>
<a id="postGrad-autopage-23"></a>


<p>
This contains all the spacy code tutorial I have done and gone through.
</p>

<a id="autoid-6"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.1:&nbsp;spaCy Basic English NLP
</p>
</div>
<pre><code class = "language-python">
# Import  the English language class
from spacy.lang.en import English


# Create the nlp object
nlp = English()


# Process a text
doc = nlp("This␣is␣a␣sentence.")


# Print the document text
print(doc.text)
</code>
</pre>

<h4 id="autosec-25">Finding words, phrases, names and concepts</h4>
<a id="postGrad-autopage-25"></a>
<h5 id="autosec-26"><span class="sectionnumber" >2.1.1&#x2003;</span>Document, spans and tokens</h5>
<a id="postGrad-autopage-26"></a>


<a id="autoid-7"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.2:&nbsp;spaCy First Token
</p>
</div>
<pre><code class = "language-python">
# Import  the English language class and create the nlp object
from spacy.lang.en import English


# Create the nlp object
nlp = English()


# Process the text
doc = nlp("I␣like␣tree␣kangaroos␣and␣narwhals.")


# Select the first token
first_token = doc[0]


# Print the first token's text
print(first_token.text)
</code>
</pre>



<a id="autoid-8"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.3:&nbsp;spaCy Slice Doc
</p>
</div>
<pre><code class = "language-python">
# Import  the English language class and create the nlp object
from spacy.lang.en import English
âĂŃ
# Create the nlp object
nlp = English()
âĂŃ
# Process the text
doc = nlp("I␣like␣tree␣kangaroos␣and␣narwhals.")
âĂŃ
# A slice of the Doc for "tree kangaroos"
tree_kangaroos = doc[2:4]
print(tree_kangaroos.text)
âĂŃ
# A slice of the Doc for "tree kangaroos and narwhals" (without the ".")
tree_kangaroos_and_narwhals = doc[2:-1]
print(tree_kangaroos_and_narwhals.text)
</code>
</pre>

<h5 id="autosec-29"><span class="sectionnumber" >2.1.2&#x2003;</span>Lexical attributes</h5>
<a id="postGrad-autopage-29"></a>


<a id="autoid-9"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.4:&nbsp;spaCy Detect Percentages
</p>
</div>
<pre
from class="programlisting">
      spacy.lang.en import English


nlp = English()


# Process the text
doc = nlp(
    "In␣1990,␣more␣than␣60%␣of␣people␣in␣East␣Asia␣were␣in␣extreme␣poverty.␣"
    "Now␣less␣than␣4%␣are."
)


# Iterate over the tokens in the doc
for token in doc:
    # Check if the token resembles a number
    if token.like_num:
         # Get the next token in the document
         next_token = doc[token.i + 1]
         # Check if the next token's text equals "%"
         if next_token.text == "%":
            print("Percentage␣found:", token.text)
</code>
</pre>

<h5 id="autosec-31"><span class="sectionnumber" >2.1.3&#x2003;</span>Loading Models</h5>
<a id="postGrad-autopage-31"></a>


<a id="autoid-10"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.5:&nbsp;spaCy Loading Models
</p>
</div>
<pre><code class = "language-python">
import  spacy


# Load the "en_core_web_sm" model
nlp = spacy.load("en_core_web_sm")


text = "ItâĂŹs␣official:␣Apple␣is␣the␣first␣U.S.␣public␣company␣to␣reach␣a␣$1␣trillion␣market␣value"


# Process the text
doc = nlp(text)


# Print the document text
print(doc.text)
</code>
</pre>

<h5 id="autosec-33"><span class="sectionnumber" >2.1.4&#x2003;</span>Linguistic Annotations</h5>
<a id="postGrad-autopage-33"></a>
<h6 id="autosec-34">Thoughts</h6>
<a id="postGrad-autopage-34"></a>


<p>
This will be useful for me to grab the percentages from finance youtube videos.
</p>

<a id="autoid-11"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.6:&nbsp;spaCy Linguistic Annotations V1
</p>
</div>
<pre><code class = "language-python">
import  spacy


nlp = spacy.load("en_core_web_sm")


text = "ItâĂŹs␣official:␣Apple␣is␣the␣first␣U.S.␣public␣company␣to␣reach␣a␣$1␣trillion␣market␣value"


# Process the text
doc = nlp(text)


for token in doc:
   # Get the token text, part-of-speech tag and dependency label
   token_text = token.text
   token_pos = token.pos_
   token_dep = token.dep_
   # This is for formatting only
   print(f"{token_text:&lt;12}{token_pos:&lt;10}{token_dep:&lt;10}")
</code>
</pre>



<a id="autoid-12"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.7:&nbsp;spaCy Linguistic Annotations V2
</p>
</div>
<pre><code class = "language-python">
import  spacy


nlp = spacy.load("en_core_web_sm")


text = "ItâĂŹs␣official:␣Apple␣is␣the␣first␣U.S.␣public␣company␣to␣reach␣a␣$1␣trillion␣market␣value"


# Process the text
doc = nlp(text)


# Iterate over the predicted entities
for ent in doc.ents:
   # Print the entity text and its label
   print(ent.text, ent.label_)
</code>
</pre>

<h5 id="autosec-37"><span class="sectionnumber" >2.1.5&#x2003;</span>Named Entities</h5>
<a id="postGrad-autopage-37"></a>


<a id="autoid-13"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.8:&nbsp;spaCy Linguistic Annotations V2
</p>
</div>
<pre><code class = "language-python">
import  spacy


nlp = spacy.load("en_core_web_sm")


text = "Upcoming␣iPhone␣X␣release␣date␣leaked␣as␣Apple␣reveals␣pre-orders"


# Process the text
doc = nlp(text)


# Iterate over the entities
for ent in doc.ents:
   # Print the entity text and label
   print(ent.text, ent.label_)


# Get the span for "iPhone X"
iphone_x = doc[1:3]


# Print the span text
print("Missing␣entity:", iphone_x.text)
</code>
</pre>

<h5 id="autosec-39"><span class="sectionnumber" >2.1.6&#x2003;</span>Matcher</h5>
<a id="postGrad-autopage-39"></a>


<a id="autoid-14"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.9:&nbsp;spaCy Matcher
</p>
</div>
<pre><code class = "language-python">
import  spacy


# Import the Matcher
from spacy.matcher import Matcher


nlp = spacy.load("en_core_web_sm")
doc = nlp("Upcoming␣iPhone␣X␣release␣date␣leaked␣as␣Apple␣reveals␣pre-orders")


# Initialize the Matcher with the shared vocabulary
matcher = Matcher(nlp.vocab)


# Create a pattern matching two tokens: "iPhone" and "X"
pattern = [{"TEXT": "iPhone"}, {"TEXT": "X"}]


# Add the pattern to the matcher
matcher.add("IPHONE_X_PATTERN", None, pattern)


# Use the matcher on the doc
matches = matcher(doc)
print("Matches:", [doc[start:end].text for match_id, start, end in matches])
</code>
</pre>



<a id="autoid-15"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.10:&nbsp;spaCy Writing Matcher
</p>
</div>
<pre><code class = "language-python">
import  spacy
from spacy.matcher import Matcher


nlp = spacy.load("en_core_web_sm")
matcher = Matcher(nlp.vocab)


doc = nlp(
    "After␣making␣the␣iOS␣update␣you␣won't␣notice␣a␣radical␣system-wide␣"
    "redesign:␣nothing␣like␣the␣aesthetic␣upheaval␣we␣got␣with␣iOS␣7.␣Most␣of␣"
    "iOS␣11's␣furniture␣remains␣the␣same␣as␣in␣iOS␣10.␣But␣you␣will␣discover␣"
    "some␣tweaks␣once␣you␣delve␣a␣little␣deeper."
)


# Write a pattern for full iOS versions ("iOS 7", "iOS 11", "iOS 10")
pattern = [{"TEXT": "iOS"}, {"IS_DIGIT": True}]


# Add the pattern to the matcher and apply the matcher to the doc
matcher.add("IOS_VERSION_PATTERN", None, pattern)
matches = matcher(doc)
print("Total␣matches␣found:", len(matches))


# Iterate over the matches and print the span text
for match_id, start, end in matches:
   print("Match␣found:", doc[start:end].text)
</code>
</pre>



<a id="autoid-16"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.11:&nbsp;spaCy Writing Matcher II
</p>
</div>
<pre><code class = "language-python">
import  spacy
from spacy.matcher import Matcher


nlp = spacy.load("en_core_web_sm")
matcher = Matcher(nlp.vocab)


doc = nlp(
    "i␣downloaded␣Fortnite␣on␣my␣laptop␣and␣can't␣open␣the␣game␣at␣all.␣Help?␣"
    "so␣when␣I␣was␣downloading␣Minecraft,␣I␣got␣the␣Windows␣version␣where␣it␣"
    "is␣the␣'.zip'␣folder␣and␣I␣used␣the␣default␣program␣to␣unpack␣it...␣do␣"
    "I␣also␣need␣to␣download␣Winzip?"
)


# Write a pattern that matches a form of "download" plus proper noun
pattern = [{"LEMMA": "download"}, {"POS": "PROPN"}]


# Add the pattern to the matcher and apply the matcher to the doc
matcher.add("DOWNLOAD_THINGS_PATTERN", None, pattern)
matches = matcher(doc)
print("Total␣matches␣found:", len(matches))


# Iterate over the matches and print the span text
for match_id, start, end in matches:
   print("Match␣found:", doc[start:end].text)
</code>
</pre>



<a id="autoid-17"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.12:&nbsp;spaCy Writing Matcher III
</p>
</div>
<pre><code class = "language-python">
import  spacy
from spacy.matcher import Matcher


nlp = spacy.load("en_core_web_sm")
matcher = Matcher(nlp.vocab)


doc = nlp(
    "Features␣of␣the␣app␣include␣a␣beautiful␣design,␣smart␣search,␣automatic␣"
    "labels␣and␣optional␣voice␣responses."
)


# Write a pattern for adjective plus one or two nouns
pattern = [{"POS": "ADJ"}, {"POS": "NOUN"}, {"POS":"NOUN", "OP": "?"}]


# Add the pattern to the matcher and apply the matcher to the doc
matcher.add("ADJ_NOUN_PATTERN", None, pattern)
matches = matcher(doc)
print("Total␣matches␣found:", len(matches))


# Iterate over the matches and print the span text
for match_id, start, end in matches:
   print("Match␣found:", doc[start:end].text)
</code>
</pre>

<h4 id="autosec-44">Large-scale data analysis with spaCy</h4>
<a id="postGrad-autopage-44"></a>


<a id="autoid-18"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.13:&nbsp;spaCy Cat hash
</p>
</div>
<pre
from class="programlisting">
      spacy.lang.en import English


nlp = English()
doc = nlp("I␣have␣a␣cat")


# Look up the hash for the word "cat"
cat_hash = nlp.vocab.strings["cat"]
print(cat_hash)


# Look up the cat_hash to get the string
cat_string = nlp.vocab.strings[cat_hash]
print(cat_string)
</code>
</pre>



<a id="autoid-19"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.14:&nbsp;spaCy Person hash
</p>
</div>
<pre
from class="programlisting">
      spacy.lang.en import English


nlp = English()
doc = nlp("David␣Bowie␣is␣a␣PERSON")


# Look up the hash for the string label "PERSON"
person_hash = nlp.vocab.strings["PERSON"]
print(person_hash)


# Look up the person_hash to get the string
person_string = nlp.vocab.strings[person_hash]
print(person_string)
</code>
</pre>



<a id="autoid-20"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.15:&nbsp;spaCy Docs, spans and entities from scratch
</p>
</div>
<pre
from class="programlisting">
      spacy.lang.en import English


nlp = English()


# Import the Doc and Span classes
from spacy.tokens import Doc, Span


words = ["I", "like", "David", "Bowie"]
spaces = [True, True, True, False]


# Create a doc from the words and spaces
doc = Doc(nlp.vocab, words=words, spaces=spaces)
print(doc.text)


# Create a span for "David Bowie" from the doc and assign it the label "PERSON"
span = Span(doc, 2, 4, label="PERSON")
print(span.text, span.label_)


# Add the span to the doc's entities
doc.ents = [span]


# Print entities' text and labels
print([(ent.text, ent.label_) for ent in doc.ents])
</code>
</pre>



<a id="autoid-21"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.16:&nbsp;spaCy Code rewrite to use spaCy functions
</p>
</div>
<pre><code class = "language-python">
# import  spacy


# nlp = spacy.load("en_core_web_sm")
# doc = nlp("Berlin is a nice city")


# # Get all tokens and part-of-speech tags
# token_texts = [token.text for token in doc]
# pos_tags = [token.pos_ for token in doc]


# for index, pos in enumerate(pos_tags):
   # # Check if the current token is a proper noun
   # if pos == "PROPN":
         # # Check if the next token is a verb
         # if pos_tags[index + 1] == "VERB":
            # result = token_texts[index]
            # print("Found proper noun before a verb:", result)


import spacy


nlp = spacy.load("en_core_web_sm")
doc = nlp("Berlin␣is␣a␣nice␣city")


# Iterate over the tokens
for token in doc:
   # Check if the current token is a proper noun
   if token.pos_ == "PROPN":
         # Check if the next token is a verb
         if doc[token.i + 1].pos_ == "VERB":
            print("Found␣proper␣noun␣before␣a␣verb:", token.text)
</code>
</pre>



<a id="autoid-22"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.17:&nbsp;spaCy Word Vectors
</p>
</div>
<pre><code class = "language-python">
import  spacy


# Load the en_core_web_md model
nlp = spacy.load("en_core_web_md")


# Process a text
doc = nlp("Two␣bananas␣in␣pyjamas")


# Get the vector for the token "bananas"
bananas_vector = doc[1].vector
print(bananas_vector)
</code>
</pre>



<a id="autoid-23"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.18:&nbsp;spaCy Similarities I
</p>
</div>
<pre><code class = "language-python">
import  spacy


nlp = spacy.load("en_core_web_md")


doc1 = nlp("It's␣a␣warm␣summer␣day")
doc2 = nlp("It's␣sunny␣outside")


# Get the similarity of doc1 and doc2
similarity = doc1.similarity(doc2)
print(similarity)
</code>
</pre>



<a id="autoid-24"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.19:&nbsp;spaCy Similarities II
</p>
</div>
<pre><code class = "language-python">
import  spacy


nlp = spacy.load("en_core_web_md")


doc = nlp("This␣was␣a␣great␣restaurant.␣Afterwards,␣we␣went␣to␣a␣really␣nice␣bar.")


# Create spans for "great restaurant" and "really nice bar"
span1 = doc[3:5]
span2 = doc[-4:-1]


# Get the similarity of the spans
similarity = span1.similarity(span2)
print(similarity)
</code>
</pre>



<a id="autoid-25"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.20:&nbsp;spaCy Extracting Countries and Relationship
</p>
</div>
<pre><code class = "language-python">
import  spacy
from spacy.matcher import Matcher
âĂŃ
nlp = spacy.load("en_core_web_sm")
doc = nlp(
      "Twitch␣Prime,␣the␣perks␣program␣for␣Amazon␣Prime␣members␣offering␣free␣"
      "loot,␣games␣and␣other␣benefits,␣is␣ditching␣one␣of␣its␣best␣features:␣"
      "ad-free␣viewing.␣According␣to␣an␣email␣sent␣out␣to␣Amazon␣Prime␣members␣"
      "today,␣ad-free␣viewing␣will␣no␣longer␣be␣included␣as␣a␣part␣of␣Twitch␣"
      "Prime␣for␣new␣members,␣beginning␣on␣September␣14.␣However,␣members␣with␣"
      "existing␣annual␣subscriptions␣will␣be␣able␣to␣continue␣to␣enjoy␣ad-free␣"
      "viewing␣until␣their␣subscription␣comes␣up␣for␣renewal.␣Those␣with␣"
      "monthly␣subscriptions␣will␣have␣access␣to␣ad-free␣viewing␣until␣October␣15."
)
âĂŃ
# Create the match patterns
pattern1 = [{"LOWER": "amazon"}, {"IS_TITLE": True, "POS": "PROPN"}]
pattern2 = [{"LOWER": "ad"}, {"TEXT": "-"}, {"LOWER": "free"}, {"POS": "NOUN"}]
âĂŃ
# Initialize the Matcher and add the patterns
matcher = Matcher(nlp.vocab)
matcher.add("PATTERN1", None, pattern1)
matcher.add("PATTERN2", None, pattern2)
âĂŃ
# Iterate over the matches
for match_id, start, end in matcher(doc):
      # Print pattern string name and text of matched span
      print(doc.vocab.strings[match_id], doc[start:end].text)
</code>
</pre>



<a id="autoid-26"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.21:&nbsp;spaCy Extracting Countries and Relationship
</p>
</div>
<pre><code class = "language-python">
import  spacy
from spacy.matcher import PhraseMatcher
from spacy.tokens import Span
import json


with open("exercises/en/countries.json") as f:
   COUNTRIES = json.loads(f.read())
with open("exercises/en/country_text.txt") as f:
   TEXT = f.read()


nlp = spacy.load("en_core_web_sm")
matcher = PhraseMatcher(nlp.vocab)
patterns = list(nlp.pipe(COUNTRIES))
matcher.add("COUNTRY", None, *patterns)


# Create a doc and reset existing entities
doc = nlp(TEXT)
doc.ents = []


# Iterate over the matches
for match_id, start, end in matcher(doc):
   # Create a Span with the label for "GPE"
   span = Span(doc, start, end, label="GPE")


   # Overwrite the doc.ents and add the span
   doc.ents = list(doc.ents) + [span]


   # Get the span's root head token
   span_root_head = span.root.head
   # Print the text of the span root's head token and the span text
   print(span_root_head.text, "--&gt;", span.text)


# Print the entities in the document
print([(ent.text, ent.label_) for ent in doc.ents if ent.label_ == "GPE"])
</code>
</pre>



<a id="autoid-27"></a>


<div class="figurecaption" >

<p>
Listing&nbsp;2.22:&nbsp;spaCy Efficient Phrase
</p>
</div>
<pre><code class = "language-python">
import  json
from spacy.lang.en import English


with open("exercises/en/countries.json") as f:
   COUNTRIES = json.loads(f.read())


nlp = English()
doc = nlp("Czech␣Republic␣may␣help␣Slovakia␣protect␣its␣airspace")


# Import the PhraseMatcher and initialize it
from spacy.matcher import PhraseMatcher


matcher = PhraseMatcher(nlp.vocab)


# Create pattern Doc objects and add them to the matcher
# This is the faster version of: [nlp(country) for country in COUNTRIES]
patterns = list(nlp.pipe(COUNTRIES))
matcher.add("COUNTRY", None, *patterns)


# Call the matcher on the test document and print the result
matches = matcher(doc)
print([doc[start:end] for match_id, start, end in matches])
</code>
</pre>



</section>

</div>

</div>

<footer>

<p>
Contact Information and Copyright
</p>

</footer>


<nav class="botnavigation" ><a href="index.html" class="linkhome" >
Home</a></nav>

</body>
</html>
